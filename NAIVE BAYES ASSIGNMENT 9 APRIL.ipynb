{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3247d-09c0-4d71-8ec2-2c718afe77e8",
   "metadata": {},
   "source": [
    "## NAIVE BAYES ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe84344-da4c-45d0-ab0a-6bf1b0324ade",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d06e72-9678-46ce-bf1a-7de97dd85a9d",
   "metadata": {},
   "source": [
    "Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update the probability of an event based on new evidence or information. Bayes' theorem can be stated as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "* P(A|B) is the conditional probability of event A given event B has occurred.\n",
    "* P(B|A) is the conditional probability of event B given event A has occurred.\n",
    "* P(A) and P(B) are the probabilities of events A and B, respectively.\n",
    "\n",
    "In simple terms, Bayes' theorem allows us to calculate the probability of event A happening given that event B has occurred. It is derived from basic probability rules and provides a formal framework for updating beliefs or hypotheses based on new evidence.\n",
    "\n",
    "Bayes' theorem has applications in various fields, including statistics, machine learning, data science, and artificial intelligence. It forms the foundation for Bayesian inference, a powerful approach for making probabilistic inferences and reasoning under uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f802f5b-d8f5-4302-80bb-2ba8e6bf6bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de16469a-20d6-4ec6-9a07-5b597c63906d",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55162791-a189-4f7f-ab66-2f5124f28f0c",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "In this formula:\n",
    "\n",
    "P(A|B) represents the conditional probability of event A given event B.\n",
    "\n",
    "P(B|A) represents the conditional probability of event B given event A.\n",
    "\n",
    "P(A) represents the probability of event A occurring.\n",
    "\n",
    "P(B) represents the probability of event B occurring.\n",
    "\n",
    "Bayes' theorem allows us to update our belief or estimate of the probability of event A occurring, given new evidence in the form of event B. It provides a mathematical framework for incorporating new information into our prior beliefs.\n",
    "\n",
    "Note that in practice, calculating the probabilities P(A|B) and P(B|A) often requires additional assumptions or knowledge about the specific problem at hand. These probabilities can be estimated from data or modeled using statistical techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ab2fa-ede4-46f0-bfe4-3ce654ab039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c7a9739-3aa3-4658-935f-9915a9e98c09",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63349df4-9ae2-4ef5-afad-942a99dcde80",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice in various fields, including statistics, machine learning, data science, and artificial intelligence. Here are a few common applications of Bayes' theorem:\n",
    "\n",
    "Bayesian Inference: Bayes' theorem forms the foundation of Bayesian inference, a powerful statistical framework for updating beliefs or making inferences based on new evidence. It allows for the incorporation of prior knowledge and the iterative refinement of probabilities as new data becomes available.\n",
    "\n",
    "Medical Diagnosis: Bayes' theorem is applied in medical diagnosis to assess the probability of a disease given certain symptoms or test results. It helps in updating the initial probability of a disease based on the observed symptoms, medical history, and diagnostic test outcomes.\n",
    "\n",
    "Spam Filtering: Bayes' theorem is used in spam filtering algorithms to classify emails as spam or non-spam. The probabilities of certain words or features occurring in spam or non-spam emails are calculated, and Bayes' theorem is employed to update the probability of an email being spam given the presence of those features.\n",
    "\n",
    "Document Classification: Bayes' theorem is utilized in text classification tasks, such as sentiment analysis or topic identification. By modeling the conditional probabilities of words or features given certain classes, Bayes' theorem can be used to determine the most likely class for a given document.\n",
    "\n",
    "Machine Learning: Bayes' theorem is used in various machine learning algorithms, especially in Bayesian machine learning approaches. It helps in estimating model parameters, making predictions, and updating beliefs in a principled probabilistic framework.\n",
    "\n",
    "These are just a few examples, and Bayes' theorem finds applications in a wide range of domains where probabilistic reasoning and updating of beliefs based on evidence are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a0ee8-de9a-4e02-a0c5-6fd1d63cd248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb16c00e-c57c-4a84-b844-d41874287224",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8f2fc-1333-4964-89ba-17dbec009a4b",
   "metadata": {},
   "source": [
    "Bayes' theorem and conditional probability are closely related concepts. Conditional probability refers to the probability of an event A occurring given that another event B has already occurred, and it is denoted as P(A|B). Bayes' theorem provides a mathematical formula to calculate this conditional probability.\n",
    "\n",
    "Bayes' theorem can be expressed as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Here, P(A|B) represents the conditional probability of event A given event B has occurred, P(B|A) represents the conditional probability of event B given event A has occurred, P(A) represents the probability of event A occurring, and P(B) represents the probability of event B occurring.\n",
    "\n",
    "In other words, Bayes' theorem allows us to update our initial belief or probability of event A given new evidence in the form of event B. It combines the prior probability of A (P(A)) with the likelihood of B given A (P(B|A)) and the overall likelihood of B (P(B)) to calculate the updated probability of A given B (P(A|B)).\n",
    "\n",
    "Conditional probability is a fundamental concept that forms the basis of Bayes' theorem. Bayes' theorem provides a formal mathematical framework for reasoning about conditional probabilities and updating beliefs based on new evidence. It enables the incorporation of prior knowledge or beliefs, making it a powerful tool in probabilistic reasoning, inference, and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a32ba-95c2-4197-bf7d-5c59d7520e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7a8f92-b5c7-44ae-89a5-2bd97cf7b619",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d96f33-fe55-45ba-8177-7a6a1bd843ff",
   "metadata": {},
   "source": [
    "When choosing a type of Naive Bayes classifier for a given problem, it is important to consider the characteristics of the data and the assumptions made by each classifier variant. The three commonly used types of Naive Bayes classifiers are Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here are some factors to consider when selecting a Naive Bayes classifier:\n",
    "\n",
    "1. Nature of the features: The choice of classifier depends on the nature of the features in your dataset.\n",
    "\n",
    "Gaussian Naive Bayes assumes that the continuous features follow a Gaussian (normal) distribution.\n",
    "Multinomial Naive Bayes is suitable for discrete features, such as word frequencies in text classification.\n",
    "Bernoulli Naive Bayes is appropriate when dealing with binary features, such as presence or absence of certain words.\n",
    "\n",
    "2. Assumptions about feature independence: Naive Bayes classifiers assume that features are conditionally independent given the class label. This means that the presence or absence of one feature does not affect the presence or absence of other features.\n",
    "\n",
    "Gaussian Naive Bayes assumes continuous features are independent and follow a Gaussian distribution.\n",
    "Multinomial Naive Bayes assumes discrete features (e.g., word counts) are independent and follow a multinomial distribution.\n",
    "Bernoulli Naive Bayes assumes binary features are independent and follow a Bernoulli distribution.\n",
    "\n",
    "3. Size of the dataset: The size of your dataset can also influence the choice of classifier.\n",
    "\n",
    "Gaussian Naive Bayes works well with small to moderate-sized datasets.\n",
    "Multinomial Naive Bayes is commonly used for text classification tasks with large, sparse feature spaces.\n",
    "Bernoulli Naive Bayes is also suitable for text classification tasks but with binary features.\n",
    "\n",
    "4. Performance evaluation: It's important to evaluate and compare the performance of different Naive Bayes classifiers on your specific dataset using appropriate evaluation metrics. Consider conducting experiments or using cross-validation to assess their performance and choose the variant that provides the best results.\n",
    "\n",
    "In practice, it is recommended to try multiple variants of Naive Bayes classifiers and compare their performance on your dataset to determine the most appropriate one. Additionally, consider the assumptions made by each variant and ensure they align well with the characteristics of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccc636-0214-4c6d-84cd-a7f4650f3c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50dd1f59-230f-40ff-8615-9296d59996d7",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b20258-eaca-4bf2-8a40-1ebd318b621b",
   "metadata": {},
   "source": [
    "To predict the class of the new instance using Naive Bayes, we need to calculate the posterior probabilities of the two classes (A and B) given the feature values X1 = 3 and X2 = 4.\n",
    "\n",
    "First, let's calculate the prior probabilities of each class based on the equal prior assumption:\n",
    "\n",
    "P(A) = P(B) = 0.5 (since equal prior probabilities are assumed)\n",
    "\n",
    "Next, we need to calculate the likelihoods for each class based on the given frequencies:\n",
    "\n",
    "For Class A:\n",
    "P(X1 = 3 | A) = 4/13\n",
    "P(X2 = 4 | A) = 3/13\n",
    "\n",
    "For Class B:\n",
    "P(X1 = 3 | B) = 1/7\n",
    "P(X2 = 4 | B) = 3/7\n",
    "\n",
    "Now, we can calculate the numerator of the posterior probability for each class:\n",
    "\n",
    "For Class A:\n",
    "P(A) * P(X1 = 3 | A) * P(X2 = 4 | A) = 0.5 * (4/13) * (3/13) = 0.058\n",
    "\n",
    "For Class B:\n",
    "P(B) * P(X1 = 3 | B) * P(X2 = 4 | B) = 0.5 * (1/7) * (3/7) = 0.061\n",
    "\n",
    "Finally, we compare the two posterior probabilities and classify the new instance based on the higher probability. In this case, the posterior probability for Class B is slightly higher (0.061 > 0.058), so Naive Bayes would predict the new instance to belong to Class B.\n",
    "\n",
    "Therefore, Naive Bayes would classify the new instance with features X1 = 3 and X2 = 4 as Class B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe523605-665b-4844-9962-8b7fbc25f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f35979-50ff-47e6-bdd7-6450b51207e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
